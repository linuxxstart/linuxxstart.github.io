<!doctype html><html lang=pt-br><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Cluster Elastic com Swarm e pipeline PaloAlto | Everton Cordeiro</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta name=Description content><link rel=prev href=https://linuxxstart.github.io/2019/12/docker-haproxy-consul/><link rel=canonical href=https://linuxxstart.github.io/2020/01/elastic-cluster-swarm/><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cluster Elastic com Swarm e pipeline PaloAlto"><meta name=twitter:description content="Neste post vou subir um cluster elastic, com Elasticsearch, Kibana e o Logstash (ELK). A stack da elastic é uma solução de análise de dados em tempo real, além das ferramentas acima tem o beats, que é um agente de envio de dados para o Elasticsearch ou para o Logstach.
Tenho testado o elastic stack há algumas meses para obter métricas do HAproxy e do firewall PaloAlto (vou demonstrar um pipeline), quando iniciei o teste eu subi o repo com docker-compose."><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Cluster Elastic com Swarm e pipeline PaloAlto","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/linuxxstart.github.io\/2020\/01\/elastic-cluster-swarm\/"},"image":{"@type":"ImageObject","url":"https:\/\/linuxxstart.github.io\/cover.png","width":800,"height":600},"genre":"posts","wordcount":673,"url":"https:\/\/linuxxstart.github.io\/2020\/01\/elastic-cluster-swarm\/","datePublished":"2020-01-08T21:14:32-03:00","dateModified":"2020-01-08T21:14:32-03:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"Everton Cordeiro","logo":{"@type":"ImageObject","url":"https:\/\/linuxxstart.github.io\/logo.png","width":127,"height":40}},"description":""}</script><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/css/lib/fontawesome-free/all.min.min.css><link rel=stylesheet href=/css/lib/animate/animate.min.min.css></head><body><script>window.isDark=(window.localStorage&&window.localStorage.getItem('theme'))==='dark';window.isDark&&document.body.classList.add('dark-theme');</script><div class=wrapper><nav class=navbar><div class=navbar-container><div class="navbar-header animated bounceIn"><a href=https://linuxxstart.github.io/>Everton Cordeiro</a></div><div class=navbar-menu><a class=menu-item href=https://linuxxstart.github.io/posts>Posts</a>
<a class=menu-item href=https://linuxxstart.github.io/about>About</a>
<a href=javascript:void(0); class=theme-switch><i class="fas fa-adjust fa-rotate-180 fa-fw"></i></a></div></div></nav><nav class=navbar-mobile><div class=navbar-container><div class=navbar-header><div class="navbar-header-title animated bounceIn"><a href=https://linuxxstart.github.io/>Everton Cordeiro</a></div><div class=menu-toggle id=menu-toggle><span></span><span></span><span></span></div></div><div class=navbar-menu id=mobile-menu><a class=menu-item href=https://linuxxstart.github.io/posts>Posts</a>
<a class=menu-item href=https://linuxxstart.github.io/about>About</a>
<a href=javascript:void(0); class=theme-switch><i class="fas fa-adjust fa-rotate-180 fa-fw"></i></a></div></div></nav><main class=main><div class=container><article class=post-warp><h1 class="post-title animated flipInX">Cluster Elastic com Swarm e pipeline PaloAlto</h1><div class=post-meta><div class=post-meta-main><a class=author href=https://linuxxstart.github.io/ rel=author><i class="fas fa-user-circle fa-fw"></i>&nbsp;</a></div><div class=post-meta-other><i class="far fa-calendar-alt fa-fw"></i><time datetime=2020-01-08>2020-01-08</time>&nbsp;
<i class="fas fa-pencil-alt fa-fw"></i>about 673 words&nbsp;
<i class="far fa-clock fa-fw"></i>4 min&nbsp;</div></div><div class=post-toc id=post-toc><h2 class=post-toc-title>Table of Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-arquivo-instancesyml>1. Arquivo instances.yml</a></li><li><a href=#2-arquivo-create-certsyml>2. Arquivo create-certs.yml</a></li><li><a href=#3-arquivo-docker-composeyml>3. Arquivo docker-compose.yml</a></li><li><a href=#31-master-node>3.1. Master node</a></li><li><a href=#32-kibana-e-logstash>3.2. Kibana e Logstash</a></li><li><a href=#33-redes-e-volumes>3.3. Redes e Volumes</a></li><li><a href=#4-importar-template>4. Importar template</a></li><li><a href=#5-paloalo>5. PaloAlo</a></li><li><a href=#6-kibana>6. Kibana</a></li><li><a href=#61-index-patterns>6.1 Index patterns</a></li><li><a href=#62-importando-dashboard>6.2 Importando dashboard</a></li><li><a href=#7-dashboard>7. Dashboard</a></li><li><a href=#fontes>Fontes</a></li></ul></li></ul></nav></div></div><div class=post-toc-mobile id=post-toc-mobile><details><summary><div class=post-toc-title><span>Table of Contents</span><span><i class="details icon fas fa-angle-down"></i></span></div></summary><div class=post-toc-content><nav id=TableOfContentsMobile><ul><li><ul><li><a href=#1-arquivo-instancesyml>1. Arquivo instances.yml</a></li><li><a href=#2-arquivo-create-certsyml>2. Arquivo create-certs.yml</a></li><li><a href=#3-arquivo-docker-composeyml>3. Arquivo docker-compose.yml</a></li><li><a href=#31-master-node>3.1. Master node</a></li><li><a href=#32-kibana-e-logstash>3.2. Kibana e Logstash</a></li><li><a href=#33-redes-e-volumes>3.3. Redes e Volumes</a></li><li><a href=#4-importar-template>4. Importar template</a></li><li><a href=#5-paloalo>5. PaloAlo</a></li><li><a href=#6-kibana>6. Kibana</a></li><li><a href=#61-index-patterns>6.1 Index patterns</a></li><li><a href=#62-importando-dashboard>6.2 Importando dashboard</a></li><li><a href=#7-dashboard>7. Dashboard</a></li><li><a href=#fontes>Fontes</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p><img src=https://user-images.githubusercontent.com/55243431/72045179-41e07880-3294-11ea-98f9-1dde4b29f5d9.png alt=elk+docker(1)>
Neste post vou subir um cluster elastic, com Elasticsearch, Kibana e o Logstash (ELK). A stack da elastic é uma solução de análise de dados em tempo real, além das ferramentas acima tem o beats, que é um agente de envio de dados para o Elasticsearch ou para o Logstach.</p><p>Tenho testado o elastic stack há algumas meses para obter métricas do HAproxy e do firewall PaloAlto (vou demonstrar um pipeline), quando iniciei o teste eu subi o <a href=https://github.com/linuxxstart/cluster-elastic>repo</a> com docker-compose.</p><p>A intençao agora é tentar subir como service no cluster swarm, para escalar principalmente os data nodes. Segue a <a href=https://github.com/linuxxstart/elastic-cluster-swarm>stack no swarm</a> e aguardo sugestões para melhoria da solução.</p><a class=post-dummy-target id=1-arquivo-instancesyml></a><h3>1. Arquivo instances.yml</h3><p>Vamos criar um arquivo que será usado na criação dos certificados do elastic, responsáveis pelo comunicação segura entre os nodes.
<img src=https://user-images.githubusercontent.com/55243431/72038636-e5279280-3280-11ea-8b83-fa654fbb9057.png alt=instances_01>
Como podemos ver na imagem acima, definimos dois nomes de serviços e os ips.</p><a class=post-dummy-target id=2-arquivo-create-certsyml></a><h3>2. Arquivo create-certs.yml</h3><p>Esta é o arquivo responsável por criar os certificados com os nomes dos serviços que definimos no arquivo anterior e vai gerar um volume onde estes certificados serão armazenados.
<img src=https://user-images.githubusercontent.com/55243431/72039104-911dad80-3282-11ea-90ea-720f8053a72c.png alt=certs_01></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>docker-compose -f create-certs.yml run --rm create_certs
</code></pre></td></tr></table></div></div><p>O comando acima vai gerar um container apenas para criar os certificados passando o arquivo instances.yml e gerando o volume elk_certs no docker. Este nome elk está definido do arquivo .env (COMPOSE_PROJECT_NAME=elk).</p><p><img src=https://user-images.githubusercontent.com/55243431/72039361-90394b80-3283-11ea-9f8e-3a06ac73f7d8.png alt=certs_02></p><a class=post-dummy-target id=3-arquivo-docker-composeyml></a><h3>3. Arquivo docker-compose.yml</h3><p>Agora vamos falar de algumas partes do arquivo de criação da stack de serviços.</p><a class=post-dummy-target id=31-master-node></a><h3>3.1. Master node</h3><p><img src=https://user-images.githubusercontent.com/55243431/72039983-d1325f80-3285-11ea-9bb0-a94317b0ea93.png alt=compose_01></p><p>Definindo as configuração do arquivo elasticsearch.yml.</p><ul><li><p><strong>node.name:</strong> Definindo o nome que do node elastic, estou usando o nome do service mais a task que corresponderá ao numero da réplica.</p></li><li><p><strong>cluster.name:</strong> Definir o nome do cluster.</p></li><li><p><strong>node.master:</strong> Será um master node.</p></li><li><p><strong>discovery.seed_hosts:</strong> Faz uma varredura na na porta 9300 pelos node que devem ser master. Usei a tasks.master.</p></li><li><p><strong>cluster.initial_master_nodes:</strong> Definir os node master. Ainda estudando uma solução para varedurada da rede, quando usei a tasks.master o cluster não subiu.</p></li><li><p><strong>xpack.monitoring.collection.enabled:</strong> Habilita o monitoramento do cluster.</p></li><li><p><strong>xpack.license.self_generated.type:</strong> Habilita a licença básica.</p></li><li><p><strong>xpack.security.enabled:</strong> Habilitando a comunicação entre os node de forma segura e com isso é habilitado a autenticação no kibana e permitindo perfis de acesso.</p></li><li><p><strong>volumes:</strong> Aqui defino um volume para a criação dos arquivo de configução e a montagem do volume dos certificados.</p></li></ul><p>As configurações do sevice data node são parecidas, mudando apenas as nomeclaturos do service e do certificado.</p><a class=post-dummy-target id=32-kibana-e-logstash></a><h3>3.2. Kibana e Logstash</h3><p><img src=https://user-images.githubusercontent.com/55243431/72080021-c524bd00-32da-11ea-8d96-9b30a8ab4222.png alt=logstash_kibana_01>
Aqui defino os arquivos de configuração do kibana.yml, onde tem a conexão com o elastic:</p><ul><li>elasticsearch.hosts: [ &ldquo;http://master:9200/&rdquo; ]</li></ul><p>E os arquivos de configurações logstash.yml e o pipeline do paloalo.</p><a class=post-dummy-target id=33-redes-e-volumes></a><h3>3.3. Redes e Volumes</h3><p><img src=https://user-images.githubusercontent.com/55243431/72041540-9b43aa00-328a-11ea-9d76-0434a9686fa2.png alt=compose_02></p><p>Criando uma rede overlay para o cluster swarm, definindo o volume &ldquo;elk_certs&rdquo; como externo e os volumes &ldquo;master&rdquo; e &ldquo;data&rdquo; serão criados de acordo com o nome do serviço o número da réplica.
<img src=https://user-images.githubusercontent.com/55243431/72041808-43f20980-328b-11ea-8dc5-5f73b5e8386b.png alt=volumes_01></p><p>Agora basta fazer o deploy da stack que o cluster vai subir. 🙏 🤞</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>docker stack deploy -c docker-compose.yml elk
</code></pre></td></tr></table></div></div><a class=post-dummy-target id=4-importar-template></a><h3>4. Importar template</h3><p>Vamos copiar e depois impontando index templates do PaloAlto no Elasticsearch.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>docker cp traffic.json elk_master.1:/
docker cp threat.json elk_master.1:/
docker exec -ti elk_master.1 curl -XPUT -u elastic:Senha123 http://127.0.0.1:9200/_template/panos-traffic?pretty -H &#39;Content-Type: application/json&#39; -d@/traffic.json
docker exec -ti elk_master.1 curl -XPUT -u elastic:Senha123 http://127.0.0.1:9200/_template/panos-threat?pretty -H &#39;Content-Type: application/json&#39; -d@/threat.json
</code></pre></td></tr></table></div></div><a class=post-dummy-target id=5-paloalo></a><h3>5. PaloAlo</h3><p>Configuar o envio de syslog do firewall para o Logstash.
<img src=https://user-images.githubusercontent.com/55243431/72042354-127a3d80-328d-11ea-8ff6-979dea5075ee.png alt=paloalto_02></p><ul><li>porta UDP 5514</li><li>format BSD</li><li>facility LOG_USER</li></ul><p><img src=https://user-images.githubusercontent.com/55243431/72042338-02625e00-328d-11ea-8016-e0824633e2d1.png alt=paloalto_01></p><a class=post-dummy-target id=6-kibana></a><h3>6. Kibana</h3><p>Agora vamos acessar o Kibana, mostrar o monitoring, configurar os index patterns e importar os dashboard.
O usuário de acesso é elastic.
<img src=https://user-images.githubusercontent.com/55243431/72042684-f4f9a380-328d-11ea-8237-51e6a10bfc83.png alt=kibana_01></p><p>Após logar vamos em monitoring na aba esquerda e veremos a saúde do nosso cluster. Essa opção nós habilitamos na configuração do elasticsearch.yml.</p><ul><li><strong>xpack.monitoring.collection.enabled</strong></li></ul><p><img src=https://user-images.githubusercontent.com/55243431/72081442-3cf3e700-32dd-11ea-880d-ae07aa10d930.png alt=kibana_02></p><p>Temos 4 nodes, 2 master e 2 data.
<img src=https://user-images.githubusercontent.com/55243431/72081492-585ef200-32dd-11ea-9f80-4bc5a1021840.png alt=kibana_03></p><p>Após fazer o &ldquo;scale&rdquo; do serviço data o cluster é atualizado e passamos a ter 5 nodes, sendo 3 data.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>docker service scale elk_data=3
</code></pre></td></tr></table></div></div><p><img src=https://user-images.githubusercontent.com/55243431/72081642-9a883380-32dd-11ea-8def-d088728ae4ea.png alt=kibana_04></p><a class=post-dummy-target id=61-index-patterns></a><h3>6.1 Index patterns</h3><p>Clique em Management > index patterns e depois create
<img src=https://user-images.githubusercontent.com/55243431/72042895-7fda9e00-328e-11ea-8174-9bb149aed636.png alt=index_patterns_01></p><p>Agora vamos criar os index:</p><ul><li>panos-system-*</li><li>panos-threat-*</li><li>panos-config-*</li><li>panos-traffic-*</li></ul><p><img src=https://user-images.githubusercontent.com/55243431/72043082-00010380-328f-11ea-922d-0de4575882b9.png alt=index_patterns_02></p><p><img src=https://user-images.githubusercontent.com/55243431/72043102-0c855c00-328f-11ea-8364-054ff7b7c5f0.png alt=index_patterns_03></p><a class=post-dummy-target id=62-importando-dashboard></a><h3>6.2 Importando dashboard</h3><p>Clique em Management > Saved objects e depois em import
<img src=https://user-images.githubusercontent.com/55243431/72043371-c11f7d80-328f-11ea-959b-da65c4e23249.png alt=danshboar_01></p><a class=post-dummy-target id=7-dashboard></a><h3>7. Dashboard</h3><p><img src=https://user-images.githubusercontent.com/55243431/72043701-95e95e00-3290-11ea-80d7-3882b0b20efa.png alt=dashboard_02></p><p><img src=https://user-images.githubusercontent.com/55243431/72043719-a3064d00-3290-11ea-8ae4-690b7894da4b.png alt=dashboard_03></p><a class=post-dummy-target id=fontes></a><h3>Fontes</h3><ul><li><a href=https://github.com/sm-biz/paloalto-elasticstack-viz>https://github.com/sm-biz/paloalto-elasticstack-viz</a></li><li><a href=https://github.com/deviantony/docker-elk/wiki/Elasticsearch-cluster>https://github.com/deviantony/docker-elk/wiki/Elasticsearch-cluster</a></li><li><a href=https://github.com/elastic/elasticsearch-docker/issues/91>https://github.com/elastic/elasticsearch-docker/issues/91</a></li><li><a href=https://www.elastic.co/pt/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash>https://www.elastic.co/pt/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash</a></li><li><a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls-docker.html>https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls-docker.html</a></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>This article is updated with 2020-01-08</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=https://linuxxstart.github.io/2020/01/elastic-cluster-swarm/index.md target=_blank></a></span></div><div class=post-info-share><span><a href="//twitter.com/share?url=https%3a%2f%2flinuxxstart.github.io%2f2020%2f01%2felastic-cluster-swarm%2f&text=Cluster%20Elastic%20com%20Swarm%20e%20pipeline%20PaloAlto&via=" target=_blank title="Share on Twitter"><i class="fab fa-twitter fa-fw"></i></a><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2flinuxxstart.github.io%2f2020%2f01%2felastic-cluster-swarm%2f" target=_blank title="Share on Facebook"><i class="fab fa-facebook-square fa-fw"></i></a><a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2flinuxxstart.github.io%2f2020%2f01%2felastic-cluster-swarm%2f&title=Cluster%20Elastic%20com%20Swarm%20e%20pipeline%20PaloAlto" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin fa-fw"></i></a></span></div></div></div><div class=post-info-more><section></section><section><span><a href=javascript:window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=https://linuxxstart.github.io/>Home</a></span></section></div><div class=post-nav><a href=https://linuxxstart.github.io/2019/12/docker-haproxy-consul/ class=prev rel=prev title="HAproxy + Consul com Docker Swarm"><i class="fas fa-angle-left fa-fw"></i>HAproxy + Consul com Docker Swarm</a></div></div><div class=post-comment><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement("script");dsq.type="text/javascript";dsq.async=true;var disqus_shortname="linuxxstart";dsq.src="//"+disqus_shortname+".disqus.com/embed.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></article></div></main><footer class=footer><div class=copyright><div class=copyright-line>Powered by <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreffer">Hugo</a>&nbsp;|&nbsp;Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="external nofollow noopener noreffer">LoveIt<i class="far fa-heart fa-fw"></i></a></div><div class=copyright-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2018 - 2020</span><span class=license>&nbsp;|&nbsp;<a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer><script src=/js/lib/jquery/jquery.slim.min.min.js></script><script src=/js/lib/lazysizes/lazysizes.min.min.js></script><script src=/js/lib/smooth-scroll/smooth-scroll.polyfills.min.min.js></script><script>window.scroll=new SmoothScroll('[data-scroll]',{speed:300,speedAsDuration:true});</script><link rel=stylesheet href=/css/lib/katex/katex.min.min.css><script src=/js/lib/katex/katex.min.min.js></script><script defer src=/js/lib/katex/auto-render.min.min.js onload=renderMathInElement(document.body);></script><script src=/js/blog.min.js></script></div><a href=# class=dynamic-to-top id=dynamic-to-top data-scroll><span>&nbsp;</span></a></body></html>